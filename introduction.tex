\section{Introduction}

A Lie group is a group + a manifold (or a variety)
\begin{itemize}
  \item $e \in G$ identity element
  \item product and $x \mapsto x^{-1}$ are continuous operations
  \item $T_e(G)$, the tangent space at $e$, has a certain bilinear operation which is not associative.
\end{itemize}

\subsection{Algebras}

Let $k$ be a field (e.g. $k=\mathbb{C}$, or $k=\overline{\mathbb{F}_p}$).

\begin{definition}
  A vector space $A$ over $k$ is a \emph{$k$-algebra} if $A$ carries a binary operation $A \times A \to A$ which is $k$-bilinear:
  \begin{align*}
    (\lambda_1 x_1 + \lambda_2 x_2) \cdot y &= \lambda_1 x_1 \cdot y + \lambda_2 x_2 \cdot y\\
    x \cdot (\lambda_1 y_1 + \lambda_2 y_2) &= \lambda_1 x \cdot y_1 + \lambda_2 x \cdot  y_2
  \end{align*}
  $\forall x_i, y_i, x, y \in A, \forall \lambda_i \in k$.
\end{definition}

\begin{example}
  If $V$ is a vector space over $k$ then we give $V$ an algebra structure by:
  \[
    v \cdot w = 0 \qquad \forall v,w \in V.
  \]
  Then $V$ becomes an algebra with zero multiplication.
\end{example}

\begin{example}
  $A=M_n(k)$ is a $k$-algebra with respect to the matrix product. Bilinearity of the matrix product is proved in linear algebra.
\end{example}

\begin{remark}
  Let $A$ be a $k$-vector space with basis $\{v_1, \dots, v_n\}$ (so $\text{dim } A = n$). To each pair $(v_i,v_j)$ we assign a vector $w_{ij} \in A$. Then we define a binary operation on $A$ by the following rule:
  \[
    \left( \sum_{i=1}^n \lambda_i v_i \right) \cdot \left( \sum_{j=1}^n \mu_j v_j \right) := \sum_{i=1}^n \sum_{j=1}^n \lambda_i \mu_j w_{ij}.
  \]
  It is straight forward to check that this product is bilinear.
\end{remark}

\begin{definition}
  An algebra $A$ is called \emph{alternative} if
  \begin{align*}
    (x \cdot x) \cdot y &= x \cdot (x \cdot y)\\
    y \cdot (x \cdot x) &= (y \cdot x) \cdot x \qquad \forall x,y \in A.
  \end{align*}
\end{definition}
Examples include $\mathbb{O}$, the algebra of Cayley octonions ($\text{dim } \mathbb{O} = 8$).

\begin{definition}
  An algebra $A$ is called \emph{anticommutative} if
  \begin{equation}\label{eqn:anticommutative}
    x \cdot x = 0 \quad \forall x \in A.
  \end{equation}
  Setting $x+y$ for $x$ gives
  \[
    0 = (x+y) \cdot (x+y) = x \cdot x + x \cdot y + y \cdot x + y \cdot y
  \]
  by bilinearity, where $x \cdot x = 0$ and $y \cdot y = 0$. Hence
  \begin{equation}\label{eqn:anticommutative2}
    x \cdot y = -y \cdot x
  \end{equation}
  in any anticommutative algebra. Put $y=x$, then we get $x \cdot x = -x \cdot x$ or $2 x \cdot x = 0$. So if $\text{char}(k) \not= 2$ (i.e. $2 \not= 0$ in $k$) then Equation (\ref{eqn:anticommutative2}) implies Equation (\ref{eqn:anticommutative}).
\end{definition}

\begin{definition}
  We say that $A$ satisfies the Jacobi identity if
  \[
    x \cdot (y \cdot z) + y \cdot (z \cdot x) + z \cdot (x \cdot y) = 0
  \]
  $\forall x,y,z \in A$. We say that $A$ is a \emph{Lie algebra} if it is anticommutative and satisfies the Jacobi identity.
\end{definition}

\begin{remark}
  Lie algebras are often denoted by lower case gothic characters. The product in a Lie algebra is denoted $[x,y]$ rather than $x \cdot y$. This notation is called the \emph{Lie product} or \emph{Lie bracket}.

  $L$ is a Lie algebra if
  \begin{itemize}
    \item $[x,x] = 0$ and
    \item $[x,[y,z]] + [y,[z,x]] + [z,[x,y]] = 0 \quad \forall x,y,z \in L$.
  \end{itemize}
\end{remark}

\subsection{How to obtain Lie algebras from associative algebras}

Let $A$ be an associative algebra over $k$. We give $A$ a new product denoted by $[\cdot,\cdot]$ by,
\[
  [x,y] = x \cdot y - y \cdot x \quad \text{(the commutator product)}.
\]
The algebra obtained is denoted $A^{(-)}$.

\begin{remark}
  If $A$ is commutative then $A^{(-)}$ has zero multiplication.
\end{remark}

\begin{proposition}
  $A^{(-)}$ is a Lie algebra.
\end{proposition}

\begin{proof}
  We have $[x,x] \overset{def}{=} x \cdot x - x \cdot x = 0$ $\forall x \in A^{(-)}$, hence $A^{(-)}$ is anticommutative.

  Now let $x,y,z \in A$.
  \begin{align*}
    [x,[y,z]] + [y,[z,x]] + [z,[x,y]] &\overset{def}{=} x \cdot [y,z] - [y,z] \cdot x\\
    &+ y \cdot [z,x] - [z,x] \cdot y\\
    &+ z \cdot [x,y] - [x,y] \cdot z\\
    &= x \cdot (y \cdot z - z \cdot y) - (y \cdot z - z \cdot y) \cdot x\\
    &+ y \cdot (z \cdot x - x \cdot z) - (z \cdot x - x \cdot z) \cdot y\\
    &+ z \cdot (x \cdot y - y \cdot x) - (x \cdot y - y \cdot x) \cdot z\\
    &= xyz - xzy - yzx + zyx\\
    &+ yzx - yxz - zxy + xzy\\
    &+ zxy - zyx - xyz + yxz\\
    &= 0.
  \end{align*}
  Hence $A^{(-)}$ satisfies the Jacobi identity and thus is a Lie algebra.
\end{proof}

If $A = M_n(k)$ then $A^{(-)}$ has a special name $\mathfrak{gl}(n, k)$ the general linear Lie algebra of order $n$ over $k$.

\begin{remark}
  If $G=GL_n(\R)$, a very important Lie group, then $T_e(G) = \mathfrak{gl}(n, \R)$.
\end{remark}

\begin{definition}
	Let $V$ be an $n$ dimension vector space over $k$. We define $A(V)$ to be the space of all linear operators $A : V \to V$ on $V$. This is an associative algebra with respect to composition:
	\[
		A \circ B(v) = A(B(v)) \quad \text{for all } v \in V, \text{ for all } A, B \in A(V).
	\]
\end{definition}

\begin{definition}
	The Lie algebra $A(V)^{(-)}$ is denoted $\mathfrak{gl}(V)$, the \emph{general linear Lie algebra of $V$}. We have
	\[
		[A, B] = A \circ B - B \circ A \quad \text{for all } A, B \in \mathfrak{gl}(V).
	\]
\end{definition}

\subsection{Subalgebras and Ideals}
\begin{definition}
	Let $A$ be an algebra over $k$. A subspace $B$ of $A$ is a \emph{subalgebra} if $x \cdot y \in B$ for all $x, y \in B$.
\end{definition}

\begin{example}\hfill
	\begin{itemize}
		\item (Lazy example) If $A$ has zero multiplication, then any subspace $V$ of $A$ is a subalgebra. Indeed, if $x, y \in V$, then $x \cdot y = 0 \in V$ (since $V$ is a subspace).
		\item If $A$ is anticommutative, then for all $x \in A$ the $k$-span $kx$ is a subalgebra of $A$:
		\[
			\lambda x \circ \mu x = \lambda\mu(\underbrace{x \circ x}_{= 0}) = 0 \in kx.
		\]
	\end{itemize}
\end{example}

\begin{definition}
	A subspace $I$ of an algebra $A$ is a \emph{left ideal} if $a \cdot x \in I$ for all $a \in A$ and for all $x \in I$. \emph{Right ideals} are defined similarly.
\end{definition}

\begin{example}
	If $A = M_n(k)$ then
	\[
		I := \left\{
		\begin{pmatrix}
			\alpha_1 & 0 & \ldots & 0 \\
			\alpha_2 & 0 & \ldots & 0 \\
			\vdots	 & \vdots & \ddots & \vdots \\
			\alpha_n & 0 & \ldots & 0
		\end{pmatrix}
		\ |\ \alpha_i \in k, i \in \{1, \ldots n\}
		\right\}
	\]
	is a left ideal of $A$. Also,
	\[
		I^T = \left\{
		\begin{pmatrix}
			\alpha_1 & \alpha_2 & \ldots & \alpha_n \\
			0 & 0 & \ldots & 0 \\
			\vdots	 & \vdots & \ddots & \vdots \\
			0 & 0 & \ldots & 0
		\end{pmatrix}
		\ |\ \alpha_i \in k, i \in \{1, \ldots n\}
		\right\}
	\]
	is a right ideal of $A$.
\end{example}

\begin{remark}
	Suppose $A$ is anticommutative and $I$ is a left ideal. Then for any $a \in A$ and $x \in I$ we have $x \cdot a = - a \cdot x \in I$. Hence $I$ is a also a right ideal.
	
	i.e. If $A$ is anticommutative, there is no need to distinguish between left and right ideals. So for Lie algebras, we only say ``ideals''.
	
	Any Lie algebra $L$ has two obvious ideals: $\{0\}$ and $L$.
\end{remark}

\begin{definition}
	Let $L$ be a Lie algebra. We say:
	\begin{itemize}
		\item $x, y \in L$ \emph{commute} if $[x, y] = 0$;
		\item $L$ is \emph{abelian} if $[x, y] = 0$;
		\item $L$ is \emph{simple} if $L$ is not abelian and $\{0\}$ and $L$ are the only ideals of $L$.
	\end{itemize}
\end{definition}

One of the main problems of Lie Theory is to classify \emph{all} finite dimensional simple Lie algebras. The following table lists the mathematicians who first classified Lie algebras where $k$ has some given characteristic (below, $p$ is a prime).

\begin{center}
	\begin{tabular}{c|l}
		$\text{char}(k)$ & Classifier(s) \\
		\hline
		$0$ ($k$ is algebraically closed) & W. Killing and E. Cartan \\
		$p > 7$ & R. E. Black, R. L. Wilson and H. Strade (c. 1988) \\
		$p > 3$ & H. Strade \\
		$p = 2, 3$ & This is still an open problem.
	\end{tabular}
\end{center}

Moving on\ldots

\begin{definition}
	If $M, N$ are two subspaces of a Lie algebra $L$ then define
	\[
		[M, N] := \text{span}\{[x, y]\ |\ x \in M, y \in N\}.
	\]
\end{definition}

\begin{example}
	$[0, N] = \{0\}$.
\end{example}

In this new notation, $M$ is a subalgebra of $L$ if $[M, M] \subseteq M$.

\begin{lemma}[Lemma on two ideals]
	Let $I, J$ be two ideals of $L$. Then $I + J$ and $[I, J]$ are ideals of $L$.
	\begin{proof}
		Let $x \in I$, $y \in J$ and $a \in A$. Then
		\[
			[a, x + y] = \underbrace{[a, x]}_{\in I} + \underbrace{[a, y]}_{\in J}.
		\]
		So $[a, x + y] \in I + J$ and thus $I + J$ is an ideal.
		
		Now consider $[I, J]$. We have
		\begin{align*}
			0 &= [a, [x, y]] + [x, [y, a]] + [y, [a, x]] \quad \text{(Jacobi identity)} \\
			  &= [a, [x, y]] - [x, [a, y]] - [[a, x], y] \quad \text{(anticommutivity)} \\
		\end{align*}
		Rearranging, we have $[a, [x, y]] = [\underbrace{x}_{\in I}, \underbrace{[a, y]}_{\in J}] + [\underbrace{[a, x]}_{\in I}, \underbrace{y}_{\in J}]$.
		So $a, [x, y]] \in [I, J] + [I, J] = [I, J]$. Hence $[L, [I, J]] \subseteq [I, J]$, i.e. $[I, J]$ is an ideal.
	\end{proof}
\end{lemma}

\begin{definition}
	We say $L$ is \emph{perfect} if $L = [L, L]$. In particular, any simple Lie algebra is perfect.
\end{definition}

\begin{definition}
	The \emph{centre} of $L$, denoted $Z(L)$, is given by
	\begin{align*}
		Z(L) &= \{z \in L\ |\ [z, L] = 0\} \\
			 &= \{z \in L\ |\ [z, x] = 0 \text{ for all } x \in L\}.
	\end{align*}
	It is easy to see that $Z(L)$ is an ideal of $L$ (since $0 \in Z(L)$).
\end{definition}

\begin{example}
	We have
	\begin{align*}
		Z(\mathfrak{gl}(n, k)) &= \{A \in M_n(k)\ |\ AX = XA \text{ for all } x \in M_n(k)\} \quad \text{(by definition)} \\
			&= \{\lambda I_n\ |\ \lambda \in k\} \quad \text{(from linear algebra)}.
	\end{align*}
	So $Z(\mathfrak{gl}(n, k))$ has dimension $1$.
	
	Similarly,
	\begin{align*}
		Z(\mathfrak{gl}(V)) &= \{A \in A(V)\ |\ A \circ X = X \circ A \text{ for all } X \in A(V)\} \\
			&= \{\lambda Id_V\ |\ \lambda \in k\}
	\end{align*}
	is 1-dimensional (it is spanned by the identity operator).
\end{example}

\begin{definition}
	For $a \in L$, the \emph{centraliser} of $a \in L$ is defined
	\[
		C_L(a) := \{x \in L\ |\ [a, x] = 0\}.
	\]
\end{definition}

\begin{remark}
	If $a = 0$ then $C_L(a) = L$. More generally, $C_L(a) = L$ if and only if $a \in Z(L)$.
\end{remark}

\begin{lemma}
	For any $a \in L$, the centraliser $C_L(a)$ is a subalgebra.
	\begin{proof}
		Suppose $x, y \in C_L(a)$. Then
		\begin{align*}
			[a, \lambda x + \mu y] &= \lambda[a, x] + \mu[a, y] \quad \text{(bilinearity)} \\
				&= \lambda \cdot 0 + \mu \cdot 0 \\
				&= 0.
		\end{align*}
		So $C_L(a)$ is a subspace.
		
		Now the Jacobi identity gives:
		\begin{align*}
			[a, [x, y]] &= -[x, [y, a]] - [y, [a, x]] \\
					   &= [x, \underbrace{[a, y]}_{= 0} - [y, \underbrace{[a, x]}_{= 0}] \quad \text{(anticommutivity)} \\
					   &= [x, 0] - [y, 0] \\
					   &= 0 \quad \text{(bilinearity)}.
		\end{align*}
		Hence $C_L(a)$ is a subalgebra.
	\end{proof}
\end{lemma}

\begin{definition}
	If $A \in \mathfrak{gl}(n, k)$, where
	\[
		A =
		\begin{pmatrix}
			\alpha_{11} & \alpha_{12} & \ldots & \alpha_{1n} \\
			\alpha_{21} & \alpha_{22} & \ldots & \alpha_{2n} \\
			\vdots		& \vdots	  & \ddots & \vdots \\
			\alpha_{n1} & \alpha_{n2} & \ldots & \alpha_{nn}
		\end{pmatrix},
	\]
	then the \emph{trace} of $A$, denoted $\text{tr}(A)$, is given by
	\[
		\text{tr}(A) := \sum_{i = 1}^n{\alpha_{ii}}.
	\]
	
	From linear algebra we have $tr(A \cdot B) = tr(B \cdot A)$ for all $A, B \in \mathfrak{gl}(n, k)$. Hence
	\begin{align*}
		\text{tr}([A, B]) &= \text{tr}(AB - BA) \\
				   &= \text{tr}(AB) - \text{tr}(BA) \\
				   &= 0.
	\end{align*}
\end{definition}

\begin{definition}
	Define $\mathfrak{sl}(n, k) := \{A \in \mathfrak{gl}(n, k)\ |\ \text{tr}(A) = 0\}$, the \emph{special linear Lie algebra} of order $n$ over $k$.
\end{definition}

Note that $\text{tr} : \mathfrak{gl}(n, k) \twoheadrightarrow k$ is a surjective linear map and $\mathfrak{sl}(n, k) = \ker(\text{tr})$. By the Kernel-Image Theorem,
\[
	\dim(\mathfrak{sl}(n, k)) = \underbrace{\dim(\mathfrak{gl}(n, k))}_{= n^2} - \underbrace{\dim(k)}_{= 1} = n^2 - 1.
\]

Now we know $[\mathfrak{gl}(n, k), \mathfrak{gl}(n, k)] \subseteq \mathfrak{sl}(n, k)$. Also, $\mathfrak{sl}(n, k)$ is an ideal of $\mathfrak{sl}(n, k)$.

The case $n = 2$ is \emph{very} important. Let
\[
	L = \mathfrak{sl}(2, k) = \left\{X =
	\begin{pmatrix}
		a & b \\
		c & d
	\end{pmatrix}
	\ |\ \text{tr}(X) = 0,\ a, b, c, d \in k
	\right\}.
\]
As $\text{tr}(X) = a + d = 0$, we have $d = -a$. Thus
\[
	\mathfrak{sl}(2, k) = \left\{X =
	\begin{pmatrix}
		a & b \\
		c & -a
	\end{pmatrix}
	\ |\ a, b, c \in k
	\right\}.
\]
Now
\[
	\begin{pmatrix}
		a & b \\
		c & -a
	\end{pmatrix}
	=
	a\begin{pmatrix}
		1 & 0 \\
		0 & -1
	\end{pmatrix}
	+
	b\begin{pmatrix}
		0 & 1 \\
		0 & 0
	\end{pmatrix}
	+
	c\begin{pmatrix}
		0 & 0 \\
		1 & 0
	\end{pmatrix}.
\]
Define
\[
	h :=
	\begin{pmatrix}
		1 & 0 \\
		0 & -1
	\end{pmatrix}, \quad
	e :=
	\begin{pmatrix}
		0 & 1 \\
		0 & 0
	\end{pmatrix}, \quad
	f :=
	\begin{pmatrix}
		0 & 0 \\
		1 & 0
	\end{pmatrix}.
\]
The matrices $h, e, f$ span $\mathfrak{sl}(2, k)$ and are linearly independent, and hence form basis of $\mathfrak{sl}(2, k)$, called \emph{standard}.

We compute
\begin{align*}
	[h, e] &= \left[
	\begin{pmatrix}
		1 & 0 \\
		0 & -1
	\end{pmatrix},
	\begin{pmatrix}
		0 & 1 \\
		0 & 0
	\end{pmatrix}
	\right] \\
	&=
	\begin{pmatrix}
		1 & 0 \\
		0 & -1
	\end{pmatrix}
	\begin{pmatrix}
		0 & 1 \\
		0 & 0
	\end{pmatrix}
	-
	\begin{pmatrix}
		0 & 1 \\
		0 & 0
	\end{pmatrix}
	\begin{pmatrix}
		1 & 0 \\
		0 & -1
	\end{pmatrix} \\
	&=
	\begin{pmatrix}
		0 & 2 \\
		0 & 0
	\end{pmatrix} \\ 
	&= 2e
\end{align*}
We can also show $[h, f] = -2f$ and $[e, f] = h$. So we have
\[
\fbox{
	[h, e] = 2e, \quad [e, f] = h, \quad [h, f] = -2f
}
\]
These are known as the \emph{$\mathfrak{sl}_2$ relations}.
